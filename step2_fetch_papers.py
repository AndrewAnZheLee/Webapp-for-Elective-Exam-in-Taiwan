import json
import random
import time
import arxiv
import os
import re  # <--- æ–°å¢æ­£å‰‡è¡¨é”å¼å¥—ä»¶
from Bio import Entrez

# === è¨­å®šå€ ===
Entrez.email = "anzhe0327@gmail.com"  # è«‹å‹™å¿…å¡«å¯« emailï¼Œé€™æ˜¯ NCBI çš„è¦å®š

# 1. è¼‰å…¥èª²ç¶±
def load_syllabus():
    try:
        with open("syllabus_mapping.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ° syllabus_mapping.json")
        return None

# 2. ç‰©ç†æŠ“å–å™¨ (arXiv)
def fetch_arxiv(chapter, keyword):
    print(f"âš›ï¸  æ­£åœ¨å¾ arXiv æœå°‹ç‰©ç†è«–æ–‡: {keyword}...")
    client = arxiv.Client()
    search = arxiv.Search(
        query=f'abs:"{keyword}" OR ti:"{keyword}"',
        max_results=3,
        sort_by=arxiv.SortCriterion.SubmittedDate
    )
    
    results = []
    try:
        for result in client.results(search):
            results.append({
                "title": result.title,
                "summary": result.summary.replace("\n", " "),
                "published": result.published.strftime("%Y-%m-%d"),
                "url": result.entry_id,
                "source": "arXiv",
                "mapping_chapter": chapter,
                "mapping_keyword": keyword,
                "subject": "physics"  # â­ï¸ é—œéµï¼šæ˜ç¢ºæ¨™è¨˜ç§‘ç›®
            })
    except Exception as e:
        print(f"arXiv é€£ç·šéŒ¯èª¤: {e}")
    
    return results

# 3. ç”Ÿç‰©/åŒ–å­¸æŠ“å–å™¨ (PubMed)
def fetch_pubmed(subject, chapter, keyword):
    print(f"ğŸ§¬ æ­£åœ¨å¾ PubMed æœå°‹ {subject} è«–æ–‡: {keyword}...")
    
    try:
        # æœå°‹ ID
        handle = Entrez.esearch(db="pubmed", term=f"{keyword} AND review[Filter]", retmax=3, sort="date")
        record = Entrez.read(handle)
        handle.close()
        
        id_list = record["IdList"]
        if not id_list: return []

        # æŠ“å–å…§å®¹
        handle = Entrez.efetch(db="pubmed", id=id_list, rettype="xml", retmode="text")
        papers = Entrez.read(handle)
        handle.close()
        
        results = []
        for article in papers['PubmedArticle']:
            try:
                art = article['MedlineCitation']['Article']
                title = art['ArticleTitle']
                
                # è™•ç†æ‘˜è¦
                abstract_list = art.get('Abstract', {}).get('AbstractText', [])
                summary = " ".join([str(x) for x in abstract_list])
                if not summary: continue

                # è™•ç†æ—¥æœŸ
                pub_date = art['Journal']['JournalIssue']['PubDate']
                year = pub_date.get('Year', '2024') # é è¨­å€¼é˜²æ­¢éŒ¯èª¤
                
                pmid = article['MedlineCitation']['PMID']

                results.append({
                    "title": title,
                    "summary": summary,
                    "published": year,
                    "url": f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/",
                    "source": "PubMed",
                    "mapping_chapter": chapter,
                    "mapping_keyword": keyword,
                    "subject": subject  # â­ï¸ é—œéµï¼šæ˜ç¢ºæ¨™è¨˜ç§‘ç›®
                })
            except:
                continue
        return results

    except Exception as e:
        print(f"PubMed é€£ç·šéŒ¯èª¤: {e}")
        return []

def clean_filename(title):
    # å°‡éæ³•å­—å…ƒæ›¿æ›ç‚ºåº•ç·šï¼Œä¸¦ç§»é™¤å¤šé¤˜ç©ºç™½
    cleaned = re.sub(r'[\\/*?:"<>|]', "_", title)
    return cleaned.strip()

# === ä¸»æ§åˆ¶æµç¨‹ ===
if __name__ == "__main__":
    syllabus = load_syllabus()
    
    if syllabus:
        # A. éš¨æ©Ÿæ±ºå®šç§‘ç›®èˆ‡é—œéµå­—
        subjects = ["physics", "chemistry", "biology"]
        target_subject = random.choice(subjects)
        chapters = list(syllabus[target_subject].keys())
        random_chapter = random.choice(chapters)
        keywords = syllabus[target_subject][random_chapter]
        random_keyword = random.choice(keywords)

        print(f"ğŸ¯ ç›®æ¨™ï¼š{target_subject} | {random_keyword}")

        # B. æŠ“å–
        papers = []
        if target_subject == "physics":
            papers = fetch_arxiv(random_chapter, random_keyword)
        else:
            papers = fetch_pubmed(target_subject, random_chapter, random_keyword)
            
        # C. å­˜æª” (âš ï¸ é‡å¤§ä¿®æ”¹)
        if papers:
            target_paper = papers[0]
            
            # 1. å»ºç«‹åˆ†é¡è³‡æ–™å¤¾ï¼šä¾‹å¦‚ raw_queue/physics
            queue_dir = f"raw_queue/{target_paper['subject']}"
            os.makedirs(queue_dir, exist_ok=True)
            
            # 2. ä½¿ç”¨æ¨™é¡Œä½œç‚ºæª”å
            safe_title = clean_filename(target_paper['title'])
            
            # æª”åéé•·å¯èƒ½æœƒå ±éŒ¯ï¼Œæˆªå–å‰ 100 å­—å…ƒæ¯”è¼ƒä¿éšª
            filename = f"{queue_dir}/{safe_title[:100]}.json"
            
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(target_paper, f, indent=4, ensure_ascii=False)
                
            print(f"âœ… æŠ“å–æˆåŠŸï¼")
            print(f"ğŸ“‚ è·¯å¾‘ï¼š{filename}")
        else:
            print("âŒ æ‰¾ä¸åˆ°ç›¸é—œè«–æ–‡ã€‚")